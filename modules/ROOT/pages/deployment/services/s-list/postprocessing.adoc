= Postprocessing Service Configuration
:toc: right
:description: The Infinite Scale postprocessing service handles the coordination of asynchronous post-processing steps.

:service_name: postprocessing

== Introduction

{description} 

== General Prerequisites

To use the postprocessing service, an event system needs to be configured for all services. By default, Infinite Scale ships with a preconfigured `nats` service.

== Post-Processing Functionality

The storageprovider service (xref:{s-path}/storage-users.adoc[storage-users]) can be configured to initiate asynchronous post-processing by setting the `STORAGE_USERS_OCIS_ASYNC_UPLOADS` environment variable to `true`. If this is the case, post-processing will get initiated _after_ uploading a file and all bytes have been received.

The `postprocessing` service will then coordinate configured post-processing steps like scanning the file for viruses. During post-processing, the file will be in a `processing state` where only a limited set of actions are available.

NOTE: The processing state excludes file accessibility by users.

When all postprocessing steps have completed successfully, the file will be made accessible to users.

== Additional Prerequisites for the postprocessing Service

Once post-processing has been enabled, configuring any post-processing step will require the requested services to be enabled and preconfigured. For example, to use the `virusscan` step, one needs to have an enabled and configured `antivirus` service.

== Post-Processing Steps

The postprocessing service is individually configurable. This is achieved by allowing a list of post-processing steps to be performed in order of their appearance in the `POSTPROCESSING_STEPS` envvar. This envvar expects a comma-separated list of steps that will be executed. Currently steps known to the system are `virusscan` and `delay`. Custom steps can be added but need an existing target for processing.

=== Virus Scanning

To enable virus scanning as a post-processing step after uploading a file, the environment variable `POSTPROCESSING_STEPS` needs to contain the word `virusscan` at one location in the list of steps. As a result, each uploaded file gets scanned for viruses as part of the post-processing steps. Note that the `antivirus service` must be enabled and configured for this to work.

=== Delay

Though this is for development purposes only and NOT RECOMMENDED on production systems, setting the environment variable `POSTPROCESSING_DELAY` to a duration not equal to zero will add a delay step with the configured amount of time. Infinite Scale will continue post-processing the file after the configured delay. Use the environment variable `POSTPROCESSING_STEPS` and the keyword `delay` if you have multiple post-processing steps and want to define their order. If `POSTPROCESSING_DELAY` is set but the keyword `delay` is not contained in `POSTPROCESSING_STEPS`, it will be executed as the last post-processing step without being listed as the last one. In this case, a log entry will be written on service startup to notify the admin about the situation. That log entry can be avoided by adding the keyword `delay` to `POSTPROCESSING_STEPS`.

== Custom Post-Processing Steps

By using the envvar `POSTPROCESSING_STEPS`, custom post-processing steps can be added. Any word can be used as step name but be careful not to conflict with existing keywords like `virusscan` and `delay`. In addition, if a keyword is misspelled or the corresponding service either does not exist or does not follow the necessary event communication, the postprocessing service will wait forever to get the required response to proceed and therefore does not continue with any other processing.

=== Prerequisites

To use custom post-processing steps, you need a custom service listening to the configured event system. For more information, see xref:general-prerequisites[General Prerequisites].

=== Workflow

When defining a custom postprocessing step (eg. `"customstep"`), the postprocessing service will eventually send an event during postprocessing. The event will be of type `StartPostprocessingStep` with its field `StepToStart` set to `"customstep"`. When the service defined as custom step receives this event, it can safely execute its actions. The postprocessing service will wait until it has finished its work. The event contains further information (filename, executing user, size, ...) and also requires tokens and URLs to download the file in case byte inspection is necessary.

Once the service defined as custom step has finished its work, it should send an event of type `PostprocessingFinished` via the configured events system back to the postprocessing service. This event needs to contain a `FinishedStep` field set to `"customstep"`. It also must contain the outcome of the step, which can be one of the following:

* `delete`: Abort postprocessing, delete the file.
* `abort`: Abort postprocessing, keep the file.
* `retry`: There was a problem that was most likely temporary and may be solved by trying again after some _backoff duration_. Retry runs automatically and is defined by the backoff behavior as described below.
* `continue`: Continue postprocessing, this is the success case.

The backoff behavior as mentioned in the `retry` outcome can be configured using the `POSTPROCESSING_RETRY_BACKOFF_DURATION` and `POSTPROCESSING_MAX_RETRIES` environment variables. The backoff duration is calculated using the following formula after each failure: `backoff_duration = POSTPROCESSING_RETRY_BACKOFF_DURATION * 2^(number of failures - 1)`. This means that the time between the next round grows exponentially limited by the number of retries. Steps that still don't succeed after the maximum number of retries will be automatically moved to the `abort` state.

== CLI Commands

=== Resume Post-Processing

If post-processing fails in one step due to an unforeseen error, current uploads will not be retried automatically. A system administrator can instead run a CLI command to retry the failed upload which is a two step process:

* First, find the upload ID of the failed upload.
+
[source,bash]
----
ocis storage-users uploads list
----

* Then use the restart command to resume post-processing of the ID selected.
+
[source,bash]
----
ocis postprocessing restart -u <uploadID>
----

== Storing

The `postprocessing` service needs to store some metadata about uploads to be able to orchestrate post-processing. When running in single binary mode, the default in-memory implementation will be just fine. In distributed deployments it is recommended to use a persistent store, see below for more details.

The `postprocessing` service stores each consumed event via the configured store in `POSTPROCESSING_STORE`. Possible stores are:

include::partial$multi-location/caching-list.adoc[]
// you must not have one or more blank lines here as it breaks continuous numbering!
. When using `redis-sentinel`, the Redis master to use is configured via `POSTPROCESSING_STORE_NODES` in the form of `<sentinel-host>:<sentinel-port>/<redis-master>` like `10.10.0.200:26379/mymaster`.

== Configuration

include::partial$deployment/services/env-and-yaml.adoc[]
